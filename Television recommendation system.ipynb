{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f804faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687ad73",
   "metadata": {},
   "source": [
    "# Dataset cleaning has already done in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097ab55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Stars</th>\n",
       "      <th>MRP</th>\n",
       "      <th>Operating_system</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Picture_qualtiy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adsun</td>\n",
       "      <td>3.8</td>\n",
       "      <td>18999</td>\n",
       "      <td>Android</td>\n",
       "      <td>16 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>HD Ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adsun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29999</td>\n",
       "      <td>Android</td>\n",
       "      <td>20 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>Ultra HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adsun</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43999</td>\n",
       "      <td>Android</td>\n",
       "      <td>20 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>HD Ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adsun</td>\n",
       "      <td>3.8</td>\n",
       "      <td>21999</td>\n",
       "      <td>Android</td>\n",
       "      <td>20 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>Full HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adsun</td>\n",
       "      <td>3.8</td>\n",
       "      <td>21999</td>\n",
       "      <td>Android</td>\n",
       "      <td>20 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>Full HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Vu</td>\n",
       "      <td>4.4</td>\n",
       "      <td>75000</td>\n",
       "      <td>Android</td>\n",
       "      <td>30 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>Full HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Vu</td>\n",
       "      <td>4.3</td>\n",
       "      <td>50000</td>\n",
       "      <td>Android</td>\n",
       "      <td>40 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>Full HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Vu</td>\n",
       "      <td>4.3</td>\n",
       "      <td>60000</td>\n",
       "      <td>Android</td>\n",
       "      <td>40 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>Full HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Vu</td>\n",
       "      <td>4.4</td>\n",
       "      <td>150000</td>\n",
       "      <td>Android</td>\n",
       "      <td>40 W Speaker Output</td>\n",
       "      <td>60 Hz Refresh Rate</td>\n",
       "      <td>Full HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Vu</td>\n",
       "      <td>4.2</td>\n",
       "      <td>350000</td>\n",
       "      <td>Android</td>\n",
       "      <td>50 W Speaker Output</td>\n",
       "      <td>120 Hz Refresh Rate</td>\n",
       "      <td>Ultra HD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product_Name  Stars     MRP Operating_system              Speaker  \\\n",
       "0          Adsun    3.8   18999          Android  16 W Speaker Output   \n",
       "1          Adsun    2.0   29999          Android  20 W Speaker Output   \n",
       "2          Adsun    2.0   43999          Android  20 W Speaker Output   \n",
       "3          Adsun    3.8   21999          Android  20 W Speaker Output   \n",
       "4          Adsun    3.8   21999          Android  20 W Speaker Output   \n",
       "..           ...    ...     ...              ...                  ...   \n",
       "378           Vu    4.4   75000          Android  30 W Speaker Output   \n",
       "379           Vu    4.3   50000          Android  40 W Speaker Output   \n",
       "380           Vu    4.3   60000          Android  40 W Speaker Output   \n",
       "381           Vu    4.4  150000          Android  40 W Speaker Output   \n",
       "382           Vu    4.2  350000          Android  50 W Speaker Output   \n",
       "\n",
       "               Frequency Picture_qualtiy  \n",
       "0     60 Hz Refresh Rate       HD Ready   \n",
       "1     60 Hz Refresh Rate        Ultra HD  \n",
       "2     60 Hz Refresh Rate       HD Ready   \n",
       "3     60 Hz Refresh Rate        Full HD   \n",
       "4     60 Hz Refresh Rate        Full HD   \n",
       "..                   ...             ...  \n",
       "378   60 Hz Refresh Rate        Full HD   \n",
       "379   60 Hz Refresh Rate        Full HD   \n",
       "380   60 Hz Refresh Rate        Full HD   \n",
       "381   60 Hz Refresh Rate        Full HD   \n",
       "382  120 Hz Refresh Rate        Ultra HD  \n",
       "\n",
       "[383 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('television.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44fbec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Operating_system\n",
       " Android        250\n",
       " WebOS           56\n",
       " Tizen           53\n",
       " Google TV       10\n",
       " Linux            9\n",
       " FireTv OS 6      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Operating_system.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d891dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Operating_system = {'Android': 0, 'FireTv OS 6': 1, 'WebOS': 3, 'Tizen': 5, 'Google TV': 2, 'Linux': 4}\n",
    "Speaker={'20 W Speaker Output':0,'40 W Speaker Output':1,'24 W Speaker Output':2,'30 W Speaker Output':3,\n",
    "        '16 W Speaker Output':4,'50 W Speaker Output':5,'60 W Speaker Output':6,'100 W Speaker Output':7}\n",
    "Frequency={'60 Hz Refresh Rate':0,'50 Hz Refresh Rate':1,'120 Hz Refresh Rate':2,'100 Hz Refresh Rate':3,\n",
    "           '200 Hz Refresh Rate':4}\n",
    "Picture_qualtiy={'HD Ready ':0,\n",
    "                 'Ultra HD':1,'Full HD ':2}\n",
    "Product_Name = { 'Adsun':0,'Croma':1,'SAMSUNG':2,'LG':3,'SONY':4\n",
    ",'MOTOROLA':5,'Nokia':6,\n",
    "'TCL':7,'Vu':8,'KODAK':9,'Haier':10,'PHILIPS':11,'Thomson':12,'iFFALCON':13,'Hyundai':14,'Lloyd':15      \n",
    "    }\n",
    "df['Operating_system'] = df['Operating_system'].str.strip()\n",
    "df['Operating_system'] = df['Operating_system'].map(Operating_system)\n",
    "df['Speaker'] = df['Speaker'].map(Speaker)\n",
    "df['Frequency'] = df['Frequency'].map(Frequency)\n",
    "df['Picture_qualtiy'] = df['Picture_qualtiy'].map(Picture_qualtiy)\n",
    "df['Product_Name'] = df['Product_Name'].map(Product_Name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737a2101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Name\n",
       "0     77\n",
       "1     64\n",
       "2     53\n",
       "3     51\n",
       "4     22\n",
       "5     18\n",
       "6     14\n",
       "7     14\n",
       "8     14\n",
       "9     11\n",
       "10     9\n",
       "11     9\n",
       "12     9\n",
       "13     7\n",
       "14     6\n",
       "15     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Product_Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9add1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Name\n",
      "0     77\n",
      "1     64\n",
      "2     53\n",
      "3     51\n",
      "4     22\n",
      "5     18\n",
      "6     14\n",
      "7     14\n",
      "8     14\n",
      "9     11\n",
      "10     9\n",
      "11     9\n",
      "12     9\n",
      "13     7\n",
      "14     6\n",
      "15     5\n",
      "Name: count, dtype: int64\n",
      "Minimum class count: 5\n",
      "Resampled dataset shape: (1232, 6), (1232,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming df is your DataFrame and it has already been preprocessed\n",
    "# Separate features and target variable\n",
    "X = df.drop('Product_Name', axis=1)\n",
    "y = df['Product_Name']\n",
    "\n",
    "# Check the distribution of the classes\n",
    "class_counts = y.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Find the minimum class count\n",
    "min_class_count = class_counts.min()\n",
    "print(f'Minimum class count: {min_class_count}')\n",
    "\n",
    "# Adjust the k_neighbors parameter to be less than or equal to the minimum class count\n",
    "smote = SMOTE(random_state=42, k_neighbors=min(min_class_count - 1, 5))\n",
    "\n",
    "# Apply SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(f'Resampled dataset shape: {X_resampled.shape}, {y_resampled.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b9b6d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Name\n",
       "0     77\n",
       "1     77\n",
       "10    77\n",
       "14    77\n",
       "13    77\n",
       "9     77\n",
       "3     77\n",
       "15    77\n",
       "5     77\n",
       "6     77\n",
       "11    77\n",
       "2     77\n",
       "4     77\n",
       "7     77\n",
       "12    77\n",
       "8     77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5627cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bba5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "203d683d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.4817813765182186\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.62      0.48        13\n",
      "           1       0.33      0.23      0.27        13\n",
      "           2       0.71      0.94      0.81        18\n",
      "           3       0.94      0.80      0.86        20\n",
      "           4       0.67      0.55      0.60        11\n",
      "           5       0.23      0.16      0.19        19\n",
      "           6       0.33      0.53      0.41        15\n",
      "           7       0.58      0.41      0.48        17\n",
      "           8       0.17      0.11      0.13        18\n",
      "           9       0.60      0.17      0.26        18\n",
      "          10       0.35      0.78      0.48         9\n",
      "          11       0.14      0.06      0.08        18\n",
      "          12       0.50      0.58      0.54        19\n",
      "          13       0.50      0.75      0.60        12\n",
      "          14       0.53      0.91      0.67        11\n",
      "          15       0.50      0.50      0.50        16\n",
      "\n",
      "    accuracy                           0.48       247\n",
      "   macro avg       0.47      0.51      0.46       247\n",
      "weighted avg       0.47      0.48      0.45       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 8  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  3  0  0  1  0  0  0  0  0  1  1  0  0  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 16  1  0  0  0  0  0  0  2  0  0  0  1]\n",
      " [ 0  0  0  1  6  0  0  0  0  0  1  0  0  0  0  3]\n",
      " [ 0  0  0  0  0  3  7  0  0  0  4  0  4  1  0  0]\n",
      " [ 0  0  0  0  0  0  8  0  3  0  0  0  2  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  7  3  1  0  0  0  5  0  1]\n",
      " [ 0  0  0  0  0  3  1  1  2  0  4  0  2  3  2  0]\n",
      " [ 1  0  0  0  0  2  6  1  0  3  2  0  3  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  7  0  0  0  0  1]\n",
      " [ 0  0  4  0  0  0  1  2  4  0  0  1  0  0  4  2]\n",
      " [ 2  0  0  0  0  4  1  0  0  1  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  1  0  0  9  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0 10  0]\n",
      " [ 2  0  3  0  0  0  0  0  0  0  0  3  0  0  0  8]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.7125506072874493\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        13\n",
      "           1       0.83      0.38      0.53        13\n",
      "           2       1.00      0.94      0.97        18\n",
      "           3       0.86      0.90      0.88        20\n",
      "           4       0.75      0.82      0.78        11\n",
      "           5       0.40      0.32      0.35        19\n",
      "           6       0.67      0.53      0.59        15\n",
      "           7       0.85      0.65      0.73        17\n",
      "           8       0.71      0.28      0.40        18\n",
      "           9       0.57      0.72      0.63        18\n",
      "          10       0.57      0.89      0.70         9\n",
      "          11       0.91      0.56      0.69        18\n",
      "          12       0.52      0.84      0.64        19\n",
      "          13       0.61      0.92      0.73        12\n",
      "          14       1.00      0.91      0.95        11\n",
      "          15       0.80      1.00      0.89        16\n",
      "\n",
      "    accuracy                           0.71       247\n",
      "   macro avg       0.74      0.73      0.71       247\n",
      "weighted avg       0.74      0.71      0.70       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  5  0  0  1  0  0  0  0  0  1  0  0  0  0  2]\n",
      " [ 0  0 17  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 18  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  2  9  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  6  3  0  2  2  1  0  4  0  0  0]\n",
      " [ 0  0  0  0  0  2  8  0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 11  0  1  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  1  1  0  0  5  3  4  0  2  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0 13  0  0  4  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  5  1  1  0  0  0 10  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0 16  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0 11  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0 10  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.9068825910931174\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.91      0.77      0.83        13\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       0.95      0.95      0.95        20\n",
      "           4       0.91      0.91      0.91        11\n",
      "           5       0.92      0.63      0.75        19\n",
      "           6       0.74      0.93      0.82        15\n",
      "           7       1.00      1.00      1.00        17\n",
      "           8       1.00      0.78      0.88        18\n",
      "           9       0.85      0.94      0.89        18\n",
      "          10       0.80      0.89      0.84         9\n",
      "          11       1.00      0.89      0.94        18\n",
      "          12       0.85      0.89      0.87        19\n",
      "          13       0.92      1.00      0.96        12\n",
      "          14       0.85      1.00      0.92        11\n",
      "          15       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.91       247\n",
      "   macro avg       0.91      0.91      0.90       247\n",
      "weighted avg       0.91      0.91      0.91       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 10  0  0  1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 10  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  2  0  0  1  2  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1  0 14  1  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 17  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 16  1  0  1  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  0  0 17  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.7327935222672065\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.91      0.77      0.83        13\n",
      "           2       0.79      0.83      0.81        18\n",
      "           3       0.85      0.85      0.85        20\n",
      "           4       0.82      0.82      0.82        11\n",
      "           5       0.36      0.26      0.30        19\n",
      "           6       0.47      0.60      0.53        15\n",
      "           7       0.78      0.82      0.80        17\n",
      "           8       0.82      0.50      0.62        18\n",
      "           9       0.64      0.78      0.70        18\n",
      "          10       0.80      0.89      0.84         9\n",
      "          11       0.53      0.56      0.54        18\n",
      "          12       0.67      0.63      0.65        19\n",
      "          13       0.80      1.00      0.89        12\n",
      "          14       0.83      0.91      0.87        11\n",
      "          15       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.73       247\n",
      "   macro avg       0.75      0.76      0.75       247\n",
      "weighted avg       0.73      0.73      0.73       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 10  0  0  0  0  0  0  0  0  1  2  0  0  0  0]\n",
      " [ 0  0 15  2  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 17  2  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  9  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  5  4  1  2  1  1  1  3  0  0  0]\n",
      " [ 0  0  0  0  0  5  9  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 14  0  1  0  0  1  1  0  0]\n",
      " [ 0  0  0  0  0  3  2  1  9  1  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0 14  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  8  1  0  0  0  0]\n",
      " [ 0  0  4  0  0  1  1  1  0  0  0 10  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  2  0  0  5  0  0 12  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 10  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0 14]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.8785425101214575\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.91      0.77      0.83        13\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       0.95      0.95      0.95        20\n",
      "           4       0.90      0.82      0.86        11\n",
      "           5       0.85      0.58      0.69        19\n",
      "           6       0.62      0.87      0.72        15\n",
      "           7       0.93      0.76      0.84        17\n",
      "           8       1.00      0.78      0.88        18\n",
      "           9       0.86      1.00      0.92        18\n",
      "          10       0.90      1.00      0.95         9\n",
      "          11       0.77      0.94      0.85        18\n",
      "          12       0.89      0.89      0.89        19\n",
      "          13       0.83      0.83      0.83        12\n",
      "          14       0.92      1.00      0.96        11\n",
      "          15       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.88       247\n",
      "   macro avg       0.89      0.88      0.88       247\n",
      "weighted avg       0.89      0.88      0.88       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 10  0  0  0  0  1  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  9  0  0  0  0  0  0  1  0  0  0  1]\n",
      " [ 0  0  0  0  0 11  4  1  0  1  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0 13  0  0  0  0  1  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  1 13  0  0  0  2  0  1  0  0]\n",
      " [ 0  0  0  0  1  0  1  0 14  1  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0 17  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1  0  0  0  0  0 17  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  1  0  0  0 10  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 15]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.41295546558704455\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       1.00      0.15      0.27        13\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       0.93      0.70      0.80        20\n",
      "           4       0.50      0.18      0.27        11\n",
      "           5       0.32      0.68      0.43        19\n",
      "           6       0.33      0.27      0.30        15\n",
      "           7       0.43      0.18      0.25        17\n",
      "           8       0.33      0.11      0.17        18\n",
      "           9       0.26      0.33      0.29        18\n",
      "          10       0.19      1.00      0.32         9\n",
      "          11       0.29      0.39      0.33        18\n",
      "          12       0.48      0.53      0.50        19\n",
      "          13       0.17      0.08      0.11        12\n",
      "          14       0.50      0.91      0.65        11\n",
      "          15       1.00      0.06      0.12        16\n",
      "\n",
      "    accuracy                           0.41       247\n",
      "   macro avg       0.48      0.41      0.36       247\n",
      "weighted avg       0.50      0.41      0.38       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  1  0  0  9  1  0  0  0  0]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 14  0  0  0  0  0  0  0  6  0  0  0  0]\n",
      " [ 0  0  0  1  2  0  0  0  3  0  0  5  0  0  0  0]\n",
      " [ 0  0  0  0  0 13  0  0  0  0  3  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  9  4  0  0  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  0  0  1  0  3  1  9  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  5  2  1  2  0  4  0  2  2  0  0]\n",
      " [ 0  0  0  0  0  2  5  0  0  6  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  1  0  7  0  0  9  0]\n",
      " [ 0  0  0  0  0  7  0  0  0  2  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  2  0  5  1  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0 10  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  8  5  0  0  0  1]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15384615384615385\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.00      0.00      0.00        19\n",
      "           6       0.00      0.00      0.00        15\n",
      "           7       0.00      0.00      0.00        17\n",
      "           8       0.00      0.00      0.00        18\n",
      "           9       0.00      0.00      0.00        18\n",
      "          10       0.11      1.00      0.20         9\n",
      "          11       0.00      0.00      0.00        18\n",
      "          12       0.00      0.00      0.00        19\n",
      "          13       0.00      0.00      0.00        12\n",
      "          14       0.08      1.00      0.14        11\n",
      "          15       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.15       247\n",
      "   macro avg       0.07      0.19      0.08       247\n",
      "weighted avg       0.08      0.15      0.09       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 12  0  0  0  1  0]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  3  0  0  0 16  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  4  0  0  0 14  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  6  0  0  0 12  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  8  0  0  0  8  0]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.8906882591093117\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.91      0.77      0.83        13\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       0.90      0.95      0.93        20\n",
      "           4       0.90      0.82      0.86        11\n",
      "           5       1.00      0.63      0.77        19\n",
      "           6       0.76      0.87      0.81        15\n",
      "           7       0.94      0.94      0.94        17\n",
      "           8       0.83      0.83      0.83        18\n",
      "           9       0.89      0.94      0.92        18\n",
      "          10       0.90      1.00      0.95         9\n",
      "          11       0.83      0.83      0.83        18\n",
      "          12       0.86      0.95      0.90        19\n",
      "          13       0.83      0.83      0.83        12\n",
      "          14       0.85      1.00      0.92        11\n",
      "          15       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.89       247\n",
      "   macro avg       0.89      0.89      0.89       247\n",
      "weighted avg       0.90      0.89      0.89       247\n",
      "\n",
      "Confusion Matrix:\n",
      " [[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 10  0  0  1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  9  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  2  0  1  1  1  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0 13  0  1  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 16  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 15  1  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 17  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0 15  1  0  1  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  0  0  0 10  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9546be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9068825910931174\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.91      0.77      0.83        13\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       0.95      0.95      0.95        20\n",
      "           4       0.91      0.91      0.91        11\n",
      "           5       0.93      0.68      0.79        19\n",
      "           6       0.70      0.93      0.80        15\n",
      "           7       1.00      0.94      0.97        17\n",
      "           8       1.00      0.78      0.88        18\n",
      "           9       0.84      0.89      0.86        18\n",
      "          10       0.90      1.00      0.95         9\n",
      "          11       1.00      0.89      0.94        18\n",
      "          12       0.81      0.89      0.85        19\n",
      "          13       0.92      1.00      0.96        12\n",
      "          14       0.85      1.00      0.92        11\n",
      "          15       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.91       247\n",
      "   macro avg       0.91      0.91      0.91       247\n",
      "weighted avg       0.92      0.91      0.91       247\n",
      "\n",
      "Confusion Matrix:  [[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 10  0  0  1  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 10  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 13  2  0  0  1  1  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  1 16  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1  0 14  1  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 16  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 16  1  0  1  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  1  0  0 17  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9068825910931174"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"Report: \",classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \",confusion_matrix(y_test, y_pred))\n",
    "model.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7b3e507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 3\n",
      "Model Prediction : 3\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "print(\"Actual Label :\", y_test.iloc[10])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b8c82f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 7\n",
      "Model Prediction : 7\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "print(\"Actual Label :\", y_test.iloc[100])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[100].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c9175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SAVE FILES\n",
    "pickle.dump(scaler,open(\"scaler.pkl\",'wb'))\n",
    "pickle.dump(model,open(\"model.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d172d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open(\"scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbdefab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "SONY with probability 0.28\n",
      "LG with probability 0.20\n",
      "TCL with probability 0.16\n",
      "Hyundai with probability 0.15\n",
      "Vu with probability 0.07\n",
      "Lloyd with probability 0.05\n",
      "iFFALCON with probability 0.04\n",
      "SAMSUNG with probability 0.03\n",
      "KODAK with probability 0.02\n",
      "Adsun with probability 0.00\n",
      "Croma with probability 0.00\n",
      "MOTOROLA with probability 0.00\n",
      "Nokia with probability 0.00\n",
      "Haier with probability 0.00\n",
      "PHILIPS with probability 0.00\n",
      "Thomson with probability 0.00\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model (assuming it is saved as 'model.pkl')\n",
    "model = joblib.load('model.pkl')\n",
    "Operating_system_dict = {'Android': 0, 'FireTv OS 6': 1, 'WebOS': 3, 'Tizen': 5, 'Google TV': 2, 'Linux': 4}\n",
    "Speaker_dict = {'20 W Speaker Output': 0, '40 W Speaker Output': 1, '24 W Speaker Output': 2, '30 W Speaker Output': 3,\n",
    "                '16 W Speaker Output': 4, '50 W Speaker Output': 5, '60 W Speaker Output': 6, '100 W Speaker Output': 7}\n",
    "Frequency_dict = {'60 Hz Refresh Rate': 0, '50 Hz Refresh Rate': 1, '120 Hz Refresh Rate': 2, '100 Hz Refresh Rate': 3,\n",
    "                  '200 Hz Refresh Rate': 4}\n",
    "Picture_qualtiy_dict = {'HD Ready': 0, 'Ultra HD': 1, 'Full HD': 2}\n",
    "\n",
    "def Recommendations(Stars, MRP, Operating_system, Speaker, Frequency, Picture_qualtiy):\n",
    "    # Map the input values using the dictionaries\n",
    "    os_mapped = Operating_system_dict.get(Operating_system, None)\n",
    "    speaker_mapped = Speaker_dict.get(Speaker, None)\n",
    "    freq_mapped = Frequency_dict.get(Frequency, None)\n",
    "    pq_mapped = Picture_qualtiy_dict.get(Picture_qualtiy, None)\n",
    "    \n",
    "    # Ensure all mappings are valid\n",
    "    if None in [os_mapped, speaker_mapped, freq_mapped, pq_mapped]:\n",
    "        raise ValueError(\"One or more input values could not be mapped.\")\n",
    "    \n",
    "    # Create a feature vector (example, adjust as needed for your model)\n",
    "    input_features = [[Stars, MRP, os_mapped, speaker_mapped, freq_mapped, pq_mapped]]\n",
    "    \n",
    "    # Use the model to predict probabilities\n",
    "    probabilities = model.predict_proba(input_features)[0]\n",
    "    \n",
    "    # Class names (ensure these are in the same order as your model classes)\n",
    "    class_names = ['Adsun', 'Croma', 'SAMSUNG', 'LG', 'SONY', 'MOTOROLA', 'Nokia', 'TCL', 'Vu', 'KODAK', 'Haier', 'PHILIPS', 'Thomson', 'iFFALCON', 'Hyundai', 'Lloyd']\n",
    "    \n",
    "    # Combine class names and probabilities\n",
    "    results = list(zip(class_names, probabilities))\n",
    "    \n",
    "    # Sort results by probability in descending order\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "final_recommendations = Recommendations(Stars=3.8, MRP=18999, Operating_system='Android', Speaker='16 W Speaker Output', Frequency='60 Hz Refresh Rate', Picture_qualtiy='HD Ready')\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7553e085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Adsun with probability 0.67\n",
      "Hyundai with probability 0.15\n",
      "PHILIPS with probability 0.05\n",
      "Nokia with probability 0.03\n",
      "TCL with probability 0.03\n",
      "KODAK with probability 0.03\n",
      "Thomson with probability 0.02\n",
      "SONY with probability 0.01\n",
      "MOTOROLA with probability 0.01\n",
      "Croma with probability 0.00\n",
      "SAMSUNG with probability 0.00\n",
      "LG with probability 0.00\n",
      "Vu with probability 0.00\n",
      "Haier with probability 0.00\n",
      "iFFALCON with probability 0.00\n",
      "Lloyd with probability 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\hunter\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Load the scaler if it exists\n",
    "try:\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "except FileNotFoundError:\n",
    "    scaler = None\n",
    "\n",
    "# Dictionaries for mapping\n",
    "Operating_system_dict = {'Android': 0, 'FireTv OS 6': 1, 'WebOS': 3, 'Tizen': 5, 'Google TV': 2, 'Linux': 4}\n",
    "Speaker_dict = {'20 W Speaker Output': 0, '40 W Speaker Output': 1, '24 W Speaker Output': 2, '30 W Speaker Output': 3,\n",
    "                '16 W Speaker Output': 4, '50 W Speaker Output': 5, '60 W Speaker Output': 6, '100 W Speaker Output': 7}\n",
    "Frequency_dict = {'60 Hz Refresh Rate': 0, '50 Hz Refresh Rate': 1, '120 Hz Refresh Rate': 2, '100 Hz Refresh Rate': 3,\n",
    "                  '200 Hz Refresh Rate': 4}\n",
    "Picture_qualtiy_dict = {'HD Ready': 0, 'Ultra HD': 1, 'Full HD': 2}\n",
    "class_names = ['Adsun', 'Croma', 'SAMSUNG', 'LG', 'SONY', 'MOTOROLA', 'Nokia', 'TCL', 'Vu', 'KODAK', 'Haier', 'PHILIPS', 'Thomson', 'iFFALCON', 'Hyundai', 'Lloyd']\n",
    "\n",
    "def Recommendations(Stars, MRP, Operating_system, Speaker, Frequency, Picture_qualtiy):\n",
    "    # Map the input values using the dictionaries\n",
    "    os_mapped = Operating_system_dict.get(Operating_system, None)\n",
    "    speaker_mapped = Speaker_dict.get(Speaker, None)\n",
    "    freq_mapped = Frequency_dict.get(Frequency, None)\n",
    "    pq_mapped = Picture_qualtiy_dict.get(Picture_qualtiy, None)\n",
    "    \n",
    "    # Ensure all mappings are valid\n",
    "    if None in [os_mapped, speaker_mapped, freq_mapped, pq_mapped]:\n",
    "        raise ValueError(\"One or more input values could not be mapped.\")\n",
    "    \n",
    "    # Create a feature vector (example, adjust as needed for your model)\n",
    "    input_features = np.array([[Stars, MRP, os_mapped, speaker_mapped, freq_mapped, pq_mapped]])\n",
    "    \n",
    "    # Apply feature scaling if scaler is available\n",
    "    if scaler:\n",
    "        input_features = scaler.transform(input_features)\n",
    "    \n",
    "    # Use the model to predict probabilities\n",
    "    probabilities = model.predict_proba(input_features)[0]\n",
    "    \n",
    "    # Combine class names and probabilities\n",
    "    results = list(zip(class_names, probabilities))\n",
    "    \n",
    "    # Sort results by probability in descending order\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "final_recommendations = Recommendations(Stars=3.8, MRP=18999, Operating_system='Android', Speaker='16 W Speaker Output', Frequency='60 Hz Refresh Rate', Picture_qualtiy='HD Ready')\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability:.2f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f59ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "LG with probability 0.92\n",
      "SONY with probability 0.03\n",
      "SAMSUNG with probability 0.02\n",
      "PHILIPS with probability 0.01\n",
      "iFFALCON with probability 0.01\n",
      "Lloyd with probability 0.01\n",
      "Adsun with probability 0.0\n",
      "Croma with probability 0.0\n",
      "MOTOROLA with probability 0.0\n",
      "Nokia with probability 0.0\n",
      "TCL with probability 0.0\n",
      "Vu with probability 0.0\n",
      "KODAK with probability 0.0\n",
      "Haier with probability 0.0\n",
      "Thomson with probability 0.0\n",
      "Hyundai with probability 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\hunter\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "final_recommendations = Recommendations(Stars=4.6,\n",
    "                                        MRP=109900,\n",
    "                                        Operating_system='WebOS',\n",
    "                                        Speaker='20 W Speaker Output',\n",
    "                                        Frequency='60 Hz Refresh Rate',\n",
    "                                        Picture_qualtiy='Full HD'\n",
    "                                        )\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.6\t89990\t WebOS\t20 W Speaker Output\t60 Hz Refresh Rate\tFull HD \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
